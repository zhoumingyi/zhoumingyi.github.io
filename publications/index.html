<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Mingyi Zhou, Ph.D. </title> <meta name="author" content="Mingyi Zhou"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?dfdb959bbe17ee6063348208af305537"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zhoumingyi.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Mingyi Zhou, Ph.D. </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ICSE2025_ArkAnalyzer-480.webp 480w,/assets/img/publication_preview/ICSE2025_ArkAnalyzer-800.webp 800w,/assets/img/publication_preview/ICSE2025_ArkAnalyzer-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/ICSE2025_ArkAnalyzer.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ICSE2025_ArkAnalyzer.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2025arkanalyzerstaticanalysisframework" class="col-sm-8"> <div class="title">[ICSE-SEIP] ArkAnalyzer: The Static Analysis Framework for OpenHarmony</div> <div class="author"> Haonan Chen, Daihang Chen, Yizhuo Yang, Lingyun Xu, Liang Gao, <em>Mingyi Zhou</em>, Chunming Hu, and Li Li </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ICSE2025_ArkAnalyzer.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://gitee.com/openharmony-sig/arkanalyzer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">chen2025arkanalyzerstaticanalysisframework</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{[ICSE-SEIP] ArkAnalyzer: The Static Analysis Framework for OpenHarmony}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Haonan and Chen, Daihang and Yang, Yizhuo and Xu, Lingyun and Gao, Liang and Zhou, Mingyi and Hu, Chunming and Li, Li}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2501.05798}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.SE}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2501.05798}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ASE2024_DynaMO-480.webp 480w,/assets/img/publication_preview/ASE2024_DynaMO-800.webp 800w,/assets/img/publication_preview/ASE2024_DynaMO-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/ASE2024_DynaMO.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ASE2024_DynaMO.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/3691620.3694998" class="col-sm-8"> <div class="title">DynaMO: Protecting Mobile DL Models through Coupling Obfuscated DL Operators</div> <div class="author"> <em>Mingyi Zhou</em>, Xiang Gao, Xiao Chen, Chunyang Chen, John Grundy, and Li Li </div> <div class="periodical"> <em>In Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering</em>, Sacramento, CA, USA, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3691620.3694998" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ASE2024_DynaMO.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/zhoumingyi/DynaMO" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Deploying deep learning (DL) models on mobile applications (Apps) has become ever-more popular. However, existing studies show attackers can easily reverse-engineer mobile DL models in Apps to steal intellectual property or generate effective attacks. A recent approach, Model Obfuscation, has been proposed to defend against such reverse engineering by obfuscating DL model representations, such as weights and computational graphs, without affecting model performance. These existing model obfuscation methods use static methods to obfuscate the model representation, or they use half-dynamic methods but require users to restore the model information through additional input arguments. However, these static methods or half-dynamic methods cannot provide enough protection for on-device DL models. Attackers can use dynamic analysis to mine the sensitive information in the inference codes as the correct model information and intermediate results must be recovered at runtime for static and half-dynamic obfuscation methods. We assess the vulnerability of the existing obfuscation strategies using an instrumentation method and tool, DLModelExplorer, that dynamically extracts correct sensitive model information (i.e., weights, computational graph) at runtime. Experiments show it achieves very high attack performance (e.g., 98.76% of weights extraction rate and 99.89% of obfuscating operator classification rate). To defend against such attacks based on dynamic instrumentation, we propose DynaMO, a Dynamic Model Obfuscation strategy similar to Homomorphic Encryption. The obfuscation and recovery process can be done through simple linear transformation for the weights of randomly coupled eligible operators, which is a fully dynamic obfuscation strategy. Experiments show that our proposed strategy can dramatically improve model security compared with the existing obfuscation strategies, with only negligible overheads for on-device models. Our prototype tool is publicly available at https://github.com/zhoumingyi/DynaMO.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3691620.3694998</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhou, Mingyi and Gao, Xiang and Chen, Xiao and Chen, Chunyang and Grundy, John and Li, Li}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DynaMO: Protecting Mobile DL Models through Coupling Obfuscated DL Operators}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400712487}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3691620.3694998}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3691620.3694998}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{204–215}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{SE for AI, AI safety, on-device AI}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Sacramento, CA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{ASE '24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10.1145/3708528" class="col-sm-8"> <div class="title">LLM for Mobile: An Initial Roadmap</div> <div class="author"> Daihang Chen, Yonghui Liu, <em>Mingyi Zhou</em>, Yanjie Zhao, Haoyu Wang, Shuai Wang, Xiao Chen, Tegawende F. Bissyande, Jacques Klein, and Li Li </div> <div class="periodical"> <em>ACM Trans. Softw. Eng. Methodol.</em>, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3708528" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/TOSEM_LLM4Mobile.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>When mobile meets LLMs, mobile app users deserve to have more intelligent usage experiences. For this to happen, we argue that there is a strong need to apply LLMs for the mobile ecosystem. We therefore provide a research roadmap for guiding our fellow researchers to achieve that as a whole. In this roadmap, we sum up six directions that we believe are urgently required for research to enable native intelligence in mobile devices. In each direction, we further summarize the current research progress and the gaps that still need to be filled by our fellow researchers.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1145/3708528</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Daihang and Liu, Yonghui and Zhou, Mingyi and Zhao, Yanjie and Wang, Haoyu and Wang, Shuai and Chen, Xiao and Bissyande, Tegawende F. and Klein, Jacques and Li, Li}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LLM for Mobile: An Initial Roadmap}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1049-331X}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3708528}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3708528}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Trans. Softw. Eng. Methodol.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ISSTA2024_DLCustomCoder-480.webp 480w,/assets/img/publication_preview/ISSTA2024_DLCustomCoder-800.webp 800w,/assets/img/publication_preview/ISSTA2024_DLCustomCoder-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/ISSTA2024_DLCustomCoder.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ISSTA2024_DLCustomCoder.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/3650212.3652119" class="col-sm-8"> <div class="title">Model-less Is the Best Model: Generating Pure Code Implementations to Replace On-Device DL Models</div> <div class="author"> <em>Mingyi Zhou</em>, Xiang Gao, Pei Liu, John Grundy, Chunyang Chen, Xiao Chen, and Li Li </div> <div class="periodical"> <em>In Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis</em>, Vienna, Austria, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3650212.3652119" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ISSTA2024_DLCustomCoder.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/zhoumingyi/CustomDLCoder" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Recent studies show that on-device deployed deep learning (DL) models, such as those of Tensor Flow Lite (TFLite), can be easily extracted from real-world applications and devices by attackers to generate many kinds of adversarial and other attacks. Although securing deployed on-device DL models has gained increasing attention, no existing methods can fully prevent these attacks. Traditional software protection techniques have been widely explored. If on-device models can be implemented using pure code, such as C++, it will open the possibility of reusing existing robust software protection techniques. However, due to the complexity of DL models, there is no automatic method that can translate DL models to pure code. To fill this gap, we propose a novel method, CustomDLCoder, to automatically extract on-device DL model information and synthesize a customized executable program for a wide range of DL models. CustomDLCoder first parses the DL model, extracts its backend computing codes, configures the extracted codes, and then generates a customized program to implement and deploy the DL model without explicit model representation. The synthesized program hides model information for DL deployment environments since it does not need to retain explicit model representation, preventing many attacks on the DL model. In addition, it improves ML performance because the customized code removes model parsing and preprocessing steps and only retains the data computing process. Our experimental results show that CustomDLCoder improves model security by disabling on-device model sniffing. Compared with the original on-device platform (i.e., TFLite), our method can accelerate model inference by 21.0% and 24.3% on x86-64 and ARM64 platforms, respectively. Most importantly, it can significantly reduce memory consumption by 68.8% and 36.0% on x86-64 and ARM64 platforms, respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3650212.3652119</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhou, Mingyi and Gao, Xiang and Liu, Pei and Grundy, John and Chen, Chunyang and Chen, Xiao and Li, Li}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Model-less Is the Best Model: Generating Pure Code Implementations to Replace On-Device DL Models}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400706127}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3650212.3652119}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3650212.3652119}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{174–185}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{AI safety, SE for AI, software optimization for AI deployment}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Vienna, Austria}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{ISSTA 2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/AAAI2024_DCS2-480.webp 480w,/assets/img/publication_preview/AAAI2024_DCS2-800.webp 800w,/assets/img/publication_preview/AAAI2024_DCS2-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/AAAI2024_DCS2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="AAAI2024_DCS2.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Wu_Hayat_Zhou_Harandi_2024" class="col-sm-8"> <div class="title">Concealing Sensitive Samples against Gradient Leakage in Federated Learning</div> <div class="author"> Jing Wu, Munawar Hayat, <em>Mingyi Zhou</em>, and Mehrtash Harandi </div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1609/aaai.v38i19.30171" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/AAAI2024_DCS2.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/JingWu321/DCS-2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Wu_Hayat_Zhou_Harandi_2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Concealing Sensitive Samples against Gradient Leakage in Federated Learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{38}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/30171}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1609/aaai.v38i19.30171}</span><span class="p">,</span>
  <span class="na">abstractnote</span> <span class="p">=</span> <span class="s">{Federated Learning (FL) is a distributed learning paradigm that enhances users’ privacy by eliminating the need for clients to share raw, private data with the server.
    Despite the success, recent studies expose the vulnerability of FL to model inversion attacks, where adversaries reconstruct users’ private data via eavesdropping on the shared gradient information. We hypothesize that a key factor in the success of such attacks is the low entanglement among gradients per data within the batch during stochastic optimization. This creates a vulnerability that an adversary can exploit to reconstruct the sensitive data. Building upon this insight, we present a simple, yet effective defense strategy that obfuscates the gradients of the sensitive data with concealed samples. To achieve this, we propose synthesizing concealed samples to mimic the sensitive data at the gradient level while ensuring their visual dissimilarity from the actual sensitive data. Compared to the previous art, our empirical evaluations suggest that the proposed technique provides the strongest protection while simultaneously maintaining the FL performance. Code is located at https://github.com/JingWu321/DCS-2.}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{19}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Jing and Hayat, Munawar and Zhou, Mingyi and Harandi, Mehrtash}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{21717-21725}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ICSE2024_REOM-480.webp 480w,/assets/img/publication_preview/ICSE2024_REOM-800.webp 800w,/assets/img/publication_preview/ICSE2024_REOM-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/ICSE2024_REOM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ICSE2024_REOM.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/3597503.3639144" class="col-sm-8"> <div class="title">Investigating White-Box Attacks for On-Device Models</div> <div class="author"> <em>Mingyi Zhou</em>, Xiang Gao, Jing Wu, Kui Liu, Hailong Sun, and Li Li </div> <div class="periodical"> <em>In Proceedings of the IEEE/ACM 46th International Conference on Software Engineering</em>, Lisbon, Portugal, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3597503.3639144" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ICSE2024_REOM.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/zhoumingyi/REOM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Numerous mobile apps have leveraged deep learning capabilities. However, on-device models are vulnerable to attacks as they can be easily extracted from their corresponding mobile apps. Although the structure and parameters information of these models can be accessed, existing on-device attacking approaches only generate black-box attacks (i.e., indirect white-box attacks), which are less effective and efficient than white-box strategies. This is because mobile deep learning (DL) frameworks like TensorFlow Lite (TFLite) do not support gradient computing (referred to as non-debuggable models), which is necessary for white-box attacking algorithms. Thus, we argue that existing findings may underestimate the harm-fulness of on-device attacks. To validate this, we systematically analyze the difficulties of transforming the on-device model to its debuggable version and propose a Reverse Engineering framework for On-device Models (REOM), which automatically reverses the compiled on-device TFLite model to its debuggable version, enabling attackers to launch white-box attacks. Our empirical results show that our approach is effective in achieving automated transformation (i.e., 92.6%) among 244 TFLite models. Compared with previous attacks using surrogate models, REOM enables attackers to achieve higher attack success rates (10.23%→89.03%) with a hundred times smaller attack perturbations (1.0→0.01). Our findings emphasize the need for developers to carefully consider their model deployment strategies, and use white-box methods to evaluate the vulnerability of on-device models. Our artifacts 1 are available.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3597503.3639144</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhou, Mingyi and Gao, Xiang and Wu, Jing and Liu, Kui and Sun, Hailong and Li, Li}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Investigating White-Box Attacks for On-Device Models}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400702174}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3597503.3639144}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3597503.3639144}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/ACM 46th International Conference on Software Engineering}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{152}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Lisbon, Portugal}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{ICSE '24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ISSTA2023_ModelObfuscator-480.webp 480w,/assets/img/publication_preview/ISSTA2023_ModelObfuscator-800.webp 800w,/assets/img/publication_preview/ISSTA2023_ModelObfuscator-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/ISSTA2023_ModelObfuscator.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ISSTA2023_ModelObfuscator.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/3597926.3598113" class="col-sm-8"> <div class="title">ModelObfuscator: Obfuscating Model Information to Protect Deployed ML-Based Systems</div> <div class="author"> <em>Mingyi Zhou</em>, Xiang Gao, Jing Wu, John Grundy, Xiao Chen, Chunyang Chen, and Li Li </div> <div class="periodical"> <em>In Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis</em>, Seattle, WA, USA, Mar 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3597926.3598113" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ISSTA2023_ModelObfuscator.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/zhoumingyi/ModelObfuscator" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>More and more edge devices and mobile apps are leveraging deep learning (DL) capabilities. Deploying such models on devices – referred to as on-device models – rather than as remote cloud-hosted services, has gained popularity because it avoids transmitting user’s data off of the device and achieves high response time. However, on-device models can be easily attacked, as they can be accessed by unpacking corresponding apps and the model is fully exposed to attackers. Recent studies show that attackers can easily generate white-box-like attacks for an on-device model or even inverse its training data. To protect on-device models from white-box attacks, we propose a novel technique called model obfuscation. Specifically, model obfuscation hides and obfuscates the key information – structure, parameters and attributes – of models by renaming, parameter encapsulation, neural structure obfuscation, shortcut injection, and extra layer injection. We have developed a prototype tool ModelObfuscator to automatically obfuscate on-device TFLite models. Our experiments show that this proposed approach can dramatically improve model security by significantly increasing the difficulty of parsing models’ inner information, without increasing the latency of DL models. Our proposed on-device model obfuscation has the potential to be a fundamental technique for on-device model deployment. Our prototype tool is publicly available at https://github.com/zhoumingyi/ModelObfuscator.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3597926.3598113</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhou, Mingyi and Gao, Xiang and Wu, Jing and Grundy, John and Chen, Xiao and Chen, Chunyang and Li, Li}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ModelObfuscator: Obfuscating Model Information to Protect Deployed ML-Based Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400702211}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3597926.3598113}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3597926.3598113}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1005–1017}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{AI safety, SE for AI, model deployment, model obfuscation}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Seattle, WA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{ISSTA 2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/CVPR2020_DaST-480.webp 480w,/assets/img/publication_preview/CVPR2020_DaST-800.webp 800w,/assets/img/publication_preview/CVPR2020_DaST-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/CVPR2020_DaST.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CVPR2020_DaST.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhou2020dast" class="col-sm-8"> <div class="title">DaST: Data-Free Substitute Training for Adversarial Attacks</div> <div class="author"> <em>Mingyi Zhou</em>, Jing Wu, Yipeng Liu, Shuaicheng Liu, and Ce Zhu </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, Mar 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> <a href="https://doi.org/10.1109/CVPR42600.2020.00031" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/CVPR2020_DaST.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/zhoumingyi/DaST" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhou2020dast</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhou, Mingyi and Wu, Jing and Liu, Yipeng and Liu, Shuaicheng and Zhu, Ce}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DaST: Data-Free Substitute Training for Adversarial Attacks}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{231-240}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CVPR42600.2020.00031}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Mingyi Zhou. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>